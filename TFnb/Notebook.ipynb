{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL(Ver4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoSG9_wsUAA3",
        "colab_type": "code",
        "outputId": "cddb0dc1-fb79-4956-cb1a-d5228d879c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        " !pip3 install tensorflow==2.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=1ef0302821581ee18eae37624e0aea8a4dd67a4a1366fa95bb3694c6235d8100\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc1\n",
            "    Uninstalling tensorflow-2.2.0rc1:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc1\n",
            "Successfully installed gast-0.2.2 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSa7HgJXUaCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFv5S6L_VQcl",
        "colab_type": "code",
        "outputId": "09b307e9-c6a1-4d69-aa18-0f7c44d3a209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7gZkZz3VVpx",
        "colab_type": "code",
        "outputId": "fdfa0e1d-3211-4802-efa8-c33860afeb81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"arghyabiswas0\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"b34716e2e8673d257783d166884a382d\" # key from the json file\n",
        "!kaggle datasets download -d grassknoted/asl-alphabet # api copied from kaggle\n",
        "from zipfile import ZipFile\n",
        "file_name = \"asl-alphabet.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading asl-alphabet.zip to /content\n",
            " 98% 1.01G/1.03G [00:28<00:00, 44.1MB/s]\n",
            "100% 1.03G/1.03G [00:28<00:00, 38.2MB/s]\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jFkjSc0VX9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'asl_alphabet_train/asl_alphabet_train'\n",
        "test_dir = 'asl_alphabet_test/asl_alphabet_test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PiTARWV8VK",
        "colab_type": "code",
        "outputId": "9e6a002f-29d5-4298-b859-5e069533189b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def load_unique():\n",
        "    size_img = 64,64 \n",
        "    labels_for_plot = []\n",
        "    for folder in os.listdir(train_dir):\n",
        "        for file in os.listdir(train_dir + '/' + folder):\n",
        "            filepath = train_dir + '/' + folder + '/' + file\n",
        "            break\n",
        "    return labels_for_plot\n",
        "\n",
        "labels_for_plot = load_unique()\n",
        "print(\"unique_labels = \", labels_for_plot)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_labels =  ['O', 'B', 'space', 'J', 'nothing', 'W', 'Z', 'T', 'del', 'R', 'I', 'X', 'F', 'Q', 'M', 'C', 'G', 'D', 'P', 'E', 'Y', 'N', 'U', 'V', 'K', 'L', 'S', 'A', 'H']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8eL5ntGWLmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
        "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
        "                   'Z':25,'space':26,'del':27,'nothing':28}\n",
        "\n",
        "def load_data():\n",
        "    images = []\n",
        "    labels = []\n",
        "    size = 64,64\n",
        "    print(\"LOADING DATA FROM : \",end = \"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end = ' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            images.append(temp_img)\n",
        "            labels.append(labels_dict[folder])\n",
        "    images = np.array(images)\n",
        "    images = images.astype('float32')/255.0\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
        "    print()\n",
        "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
        "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Gec6QvWOpT",
        "colab_type": "code",
        "outputId": "5ed29b77-f9ae-4812-8ba3-057044afb32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOADING DATA FROM : O | B | space | J | nothing | W | Z | T | del | R | I | X | F | Q | M | C | G | D | P | E | Y | N | U | V | K | L | S | A | H | \n",
            "Loaded 82650 images for training, Train data shape = (82650, 64, 64, 3)\n",
            "Loaded 4350 images for testing Test data shape = (4350, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tJ_tN-TWRxY",
        "colab_type": "code",
        "outputId": "c622e1cc-cb12-4c2c-8160-26e704aca879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size = [3,3]))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size = [3,3]))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size = [3,3]))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(512, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dense(29, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size = 64, epochs = 10, validation_split = 0.2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66120 samples, validate on 16530 samples\n",
            "Epoch 1/10\n",
            "66120/66120 [==============================] - 12s 182us/sample - loss: 0.9215 - accuracy: 0.7951 - val_loss: 0.2454 - val_accuracy: 0.9805\n",
            "Epoch 2/10\n",
            "66120/66120 [==============================] - 11s 173us/sample - loss: 0.1970 - accuracy: 0.9781 - val_loss: 0.2470 - val_accuracy: 0.9541\n",
            "Epoch 3/10\n",
            "66120/66120 [==============================] - 11s 173us/sample - loss: 0.1723 - accuracy: 0.9801 - val_loss: 0.1645 - val_accuracy: 0.9786\n",
            "Epoch 4/10\n",
            "66120/66120 [==============================] - 12s 174us/sample - loss: 0.1534 - accuracy: 0.9824 - val_loss: 0.3981 - val_accuracy: 0.9290\n",
            "Epoch 5/10\n",
            "66120/66120 [==============================] - 12s 174us/sample - loss: 0.1350 - accuracy: 0.9898 - val_loss: 0.0625 - val_accuracy: 0.9991\n",
            "Epoch 6/10\n",
            "66120/66120 [==============================] - 12s 178us/sample - loss: 0.1474 - accuracy: 0.9860 - val_loss: 0.1437 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "66120/66120 [==============================] - 11s 173us/sample - loss: 0.0930 - accuracy: 0.9946 - val_loss: 0.0545 - val_accuracy: 0.9986\n",
            "Epoch 8/10\n",
            "66120/66120 [==============================] - 11s 174us/sample - loss: 0.1460 - accuracy: 0.9888 - val_loss: 0.0658 - val_accuracy: 0.9985\n",
            "Epoch 9/10\n",
            "66120/66120 [==============================] - 11s 174us/sample - loss: 0.0839 - accuracy: 0.9925 - val_loss: 0.2943 - val_accuracy: 0.9678\n",
            "Epoch 10/10\n",
            "66120/66120 [==============================] - 11s 174us/sample - loss: 0.1317 - accuracy: 0.9927 - val_loss: 0.0464 - val_accuracy: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc51befe080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN65HAqxXmQO",
        "colab_type": "text"
      },
      "source": [
        "### The following code segment is to convert the Tensorflow model that we trained into a TFLite model so that it can be implemented in an Android app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-jewo6KXXvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29YFcxpEo4q9",
        "colab_type": "code",
        "outputId": "5bb9a5db-4284-4349-a7c2-8a995ea8aa2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "ASL_SAVED_MODEL = \"saved_models/asl_aplhabet\"\n",
        "tf.keras.models.save_model(model, ASL_SAVED_MODEL,overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format='tf',\n",
        "    signatures=None,\n",
        "    options=None)\n",
        "asl_model = tf.keras.models.load_model(ASL_SAVED_MODEL,custom_objects={'KerasLayer':hub.KerasLayer},\n",
        "    compile=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_models/asl_aplhabet/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD9rs1RJpDAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/asl.tflite\"\n",
        "TFLITE_QUANT_MODEL = \"tflite_models/asl_quant.tflite\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGbpN5iOpFWm",
        "colab_type": "code",
        "outputId": "70dde153-b98e-4b38-ddab-f14c76f105f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : asl_model(x))\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "# Convert the model to quantized version with post-training quantization\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_quant_model = converter.convert()\n",
        "open(TFLITE_QUANT_MODEL, \"wb\").write(tflite_quant_model)\n",
        "print(\"TFLite models and their sizes:\")\n",
        "!ls \"tflite_models\" -lh"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFLite models and their sizes:\n",
            "total 4.6M\n",
            "-rw-r--r-- 1 root root 932K Mar 30 07:32 asl_quant.tflite\n",
            "-rw-r--r-- 1 root root 3.6M Mar 30 07:32 asl.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hAiifw3pHAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}